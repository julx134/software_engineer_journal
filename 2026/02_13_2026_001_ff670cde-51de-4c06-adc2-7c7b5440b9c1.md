# Series 001

- Initially designed the deserializer and mapper to instantiate an object for every `adv` field due to 'semantic' data format reasonings

- however, after confirming with my manager, we discussed constraints and the fact that we are going to be serving 400+ devices concurrently will not be a good design for the system because it will be 400+ object instances in memory per 1-2s.

# Series 002

- There was also an extra requirement in caching the device battery information (derived from the mqtt broker) into redis.

- However, the MQTT broker and listeners are already complicated via dynamic configuration and polymorphism + the fact that the SOSListener is also performing business-specific logic on top of mqtt message deserialization and filtering. The design was already too coupled (i.e. MQTT client management, message handling and deserialization, and sos business logic handling), that if we added a caching logic that we would have a coupled 'God' Listener.

- I suggested to leverage Spring Event capability since we were already using it in some parts of the code. We would decouple the mqtt logic (client management, subscription, and deserializing) with the business logic (i.e. caching + sos management). In that way, we have the mqtt service/infra which sole purpose is to do mqtt client management and message deserialization, and we could have the observer be correctly part of the business domain logic space.

- Diving deep --> As I was implementing the code, one of the requirements for caching was to only write new values past the expiry threshold (i.e. we set once, wait for it to expire, and then update value). However, I got to thinking about the cost of having to "reject" each public message within that period which was minimal because it was singular boolean condition check. Then I went further deeper and asked if there was a performance cost in using Spring Events, especially with our expected throughput (2000 msg/sec). From research, it seems that the Spring Bus was light enough to handle message pub and sub. So I went even deeper, and checked to see if our deserialization code could handle the expected throughput. From research, we are far optimized from it because we are using JSON Node Parsing (which is inherently expensive because you have to build a hashmap). I went to profile it and it cost us 297ms in execution time for 400 msgs.

- Sidenote --> We implemented with JSON Node which has to build a tree structure of the mqtt message first. Each primitive field is wrapped with a JSON Node equivalent and each objec is wrapped with a LinkedHashMap. This makes the memory usage huge and also more processing time due to having to initialize the node wrappers and building the tree.

- This means we can't reach our throughput because we can only theoretically calculate 1346 msg/s (attach equations here).

- To optimize the deserialization function I reviewed first how I was deserialzing things in the first place. Because I initially implemented the Data POJOs to be polymorphic, that influenced the way I deserialized the messages as well. I created a JSON node from root first using `readTree()` which was expensive. Then, I would map the correct concrete class depending on the `type` field of the message and if not present, map it to a default class. However, because I did not know the performance hit before the implementation, I was using `convertValue()` (which is also expensive) to do the mapping. I had liberally used `convertValue` to do the mapping without knowing about the performance cost. Essentially I had the following: `CPU COST = Cost(readTree()) + Cost(2*convertValue()) + Cost(N*convertValue())` per message where N is the number of elements in the `adv` array.

- To optimize the deserialization, I went first to clean up unnecessary `convertValue()` calls. Looking back, I also had the idea of instantiating the concrete classes manually rather than having Jackson do it, but I chose to keep readability over performance. Now, with the new requirement, I had to manually extract the common fields an manually instantiate the classes. I ended up having to call `readTree()` once but I converted some of the `convertValue()` to `treeTovalue()` (which is a more optimized approach) for readability purposes. I still wanted to keep some readability/jackson capability over performance because mapping everything manually would defeat the purpose of using Jackson's automatic mapping.

- The optimization resulted in a 98% (2x) faster throughput with a processing reduction of 50% (insert equations here) at 150ms execution time for 400 msg/s. This was a significant jump meaning we could handle the expected throughput without any bottlenecks.

- extra: researched about async programming and spring proxies

# Series 003

- After confirming with my manager again, it seems that he is expecting the throughput to double from 2000msg/s to 4000-5000msg/s. This means that our current deserializer is still not enough to handle the throughout

- after some research a sentence had stuck with me:
  > Designing for high throughput almost always forces you to write code that caters to how the machine wants to read data, rather than how a human wants to read the code.
